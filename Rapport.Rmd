---
title: "Rapport"
author: "Ai-Ling Nguyen Bonnet & Elena Roques"
date: "2023-12-09"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(visdat)
library(reshape2)
library(ggplot2)
library(corrplot)
library(GGally)
library(factoextra)
library(pheatmap)
library(dplyr)
#library(outliers)
library(purrr)
```

# Biostatistique : Etude du diabète

### Ai-Ling Nguyen Bonnet & Eléna Roques

```{r}
data <- read.csv('diabetes.csv')
```

# Question 0 - Prétraitement des données

```{r Données manquantes}
vis_miss(data[,-1])
```

En attendant de pouvoir extrapoler les valeurs manquantes, on enlèves les observations incomplètes.

```{r}
data = na.omit(data) #cela enlève presque la moitié des lignes -_-
#On sépare les labels des variables 
X = data[,2:(NCOL(data)-1)]
y = data[, NCOL(data)]
y = factor(y, levels = c("neg", "pos"), labels = c(0, 1))
print(X)
print(y)
```

# Question 1 - Analyse exploratoire des données

## 1.1 - Distribution des variables

1.1.
Représenter la distribution de chaque variable explicative conditionnée par la variable diabetes.
Observet- on des différences significatives ?
En utilisant les tests statistiques qui conviennent (test de student, test du χ2, . . . ), vous justifierez soigneusement vos réponses en vous appuyant sur des critères de p-value ou autre intervalle de confiance.
Dans toute la suite, vous travaillerez sur les données standardisées

Voir <https://www.datanovia.com/en/fr/lessons/test-t-dans-r/#t-test-pour-echantillons-independants> pour le t - test

Note : Le *pedigree* est un score mesurant le risque familial du diabète.

```{r Moyennes}
data %>%
  group_by(diabetes) %>%
  summarise_at( c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass","pedigree","age"),.f = list(mean = mean), na.rm = TRUE)
  #summarise_all(sd,na.rm = TRUE)
  #get_summary_stats(glucose, type = "mean_sd")
```

```{r Variances}
data %>%
  group_by(diabetes) %>%
  summarise_at( c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass","pedigree","age"),.f = list(sd = sd), na.rm = TRUE)
```

### Représentation des distributions

```{r, echo = TRUE, fig.align = 'center', fig.height = 7.5, fig.width = 7.5}
data2 <- melt(data, id = "diabetes") 
ggplot(data = data2, aes(x = diabetes, y = value, color = diabetes)) + 
  geom_boxplot(col = "black", show.legend = FALSE, outlier.colour = NA) + theme_bw() +
  geom_point(shape = 1, 
             position = position_jitterdodge(dodge.width = .6, 
                                             jitter.width = .8), 
             size = 1.8, alpha = 1, show.legend = FALSE) +
  facet_wrap(. ~ variable, scales = "free") +
  theme(strip.background = element_rect(colour = "black", fill = "white"),
        strip.text.x = element_text(size = 11),
        axis.text = element_text(size = 9), axis.title = element_text(size = 0),
        legend.position = "bottom") + xlab("") + ylab("") +
  scale_color_manual(values = c("springgreen4","firebrick3"))
```

### Test statistique

On a deux groupes selon le diabète: les négatifs, *neg*, et les positifs,*pos*, dont on voudrait regarder les différences de moyenne.
Pour cela, un test t de Student ou de Welch peut-être pertinent, pourvu que les conditions suivantes soient remplies:

1.  Indépendance des observations. Chaque sujet ne doit appartenir qu'à un seul groupe. Il n'y a aucun lien entre les observations de chaque groupe. C'est bien vérifié dans notre cas, puisque les observations ne peuvent avoir qu'un seul label *diabetes* (*pos* ou *neg*). Les observations sont faites sur des femmes différentes, supposées sans lien.
2.  Aucune valeur aberrante significative dans les deux groupes
3.  Normalité. les données pour chaque groupe devraient être distribuées approximativement normalement.

Le test de Student suppose que les variances entre les deux groupes sont similaires, ce qui n'est pas le cas du test de Welch.

#### Valeurs aberrantes

```{r Valeurs aberrantes}
# Variables à tester
variables_a_tester <- c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass", "pedigree", "age")

# Utiliser la fonction map() pour identifier les outliers pour chaque variable
outliers_list <- map(variables_a_tester, ~ data %>%
                        group_by(diabetes) %>%
                        identify_outliers(.x)%>%
                        mutate(variable = .x))

outliers_combined <- bind_rows(outliers_list, .id="Variables")%>%
  arrange(ID) %>%
  select(ID, variable,everything(), -c(Variables))%>%
  filter(is.extreme == TRUE) 
print(outliers_combined)

# Calculer le nombre de valeurs différentes dans la colonne "ID"
num_outliers <- outliers_combined %>%
  summarize(num_outliers= n_distinct(ID))

print(num_outliers)
```

Il y a 19 observations aberrantes extrêmes.
On les enlèvera de *data*.
On peut considérer qu'il n'y pas de valeurs aberrantes sur l'age ou la masse ?

#### **Normalité par groupes**

On vérifie, pour chaque variable, si les groupes de données suivent une loi normale.
On utilise à cet effet le test de Shapiro - Wilk.
Si la p-value est inférieure à 0.005, on considère que les données ne suivent pas une loi normale.

```{r Shapiro-Wilk test}


# Utiliser la fonction map() pour effectuer le test de Shapiro-Wilk sur chaque variable
shapiro_tests <- map(variables_a_tester, ~ data %>%
                      group_by(diabetes) %>%
                      summarise(p_value = shapiro.test(.[[.x]])$p.value) %>%
                      mutate(variable = .x)%>%
                      select(variable, diabetes, p_value))

# Combinez les résultats dans un tableau
shapiro_combine <- bind_rows(shapiro_tests)

# Afficher le tableau combiné
print(shapiro_combine)
```

La *p-value* est très faible pour tous les groupes donc on ne peut pas considérer de façon sûre que les données suivent une loi normale.

#### t -test

Pour évaluer les différences entre les deux groupes *pos* et *neg* selon les variables, on utilise un test statistique.

Les données ne suivent pas une loi normale, donc le test de Welch ne peut pas être utilisé de façon rigoureuse.
On fait donc un test de Wilcoxon qui est une alternative non paramétrique à ces test t pour comparer des moyennes.
On s'autorise à faire le test de Welch pour comparer les résultats.

```{r Tests statistiques}
# Variables à tester
data_clean<- anti_join(data, outliers_combined, by = "ID")
variables_a_tester <- c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass", "pedigree", "age")

# Le t-test classique - version par défaut de Welch
welch_tests <- map(variables_a_tester, ~ data_clean %>%
                    t_test(as.formula(paste(.x, "~ diabetes"))) %>%
                    add_significance())
welch_res <- bind_rows(welch_tests)%>% 
    select(-one_of("group1", "group2", "statistic","df"))%>%
    rename('Welch - p_value' = 'p', "Welch Signif" = 'p.signif')


# Le test de Wilcox pour des données non normalisées 
wilcox_tests <- map(variables_a_tester, ~ data_clean %>%
                    wilcox_test(as.formula(paste(.x, "~ diabetes"))) %>%
                    add_significance())
wilcox_res <- bind_rows(wilcox_tests)%>% 
    select(-one_of("group1", "group2", "statistic"))%>%
  rename('Wilcox - p_value' = 'p', "Wilcox Signif" = 'p.signif')

test_res <- left_join(welch_res, wilcox_res)
print(test_res)
```

Pour chaque variables, et quelque soit le test, la *p-value* est très faible (inférieure à 0.001) donc on peut rejeter l'hypothèse que les groupes *positifs* et *négatifs* ont la même moyenne.

Il est donc raisonnable de considérer que pour chaque variable, la différence entre les deux groupes est significative.

## 1.2 - Analyse en composante principale

On fait l'analyse en enlevant les valeurs NA.
[Voir question 0 pour remplacer les NA par des valeurs numériques].
On enlève la colonne ID qui n'a pas d'interêt explicatif.
Les données sont normalisées et centrées au sein de la fonction pca.

```{r, echo = TRUE, fig.align = 'center', fig.height = 5.5, fig.width = 5.5}
fit.pca <- prcomp(X, center = TRUE, scale = TRUE)
```

```{r}
summary(fit.pca)
```

```{r}
print(head(fit.pca$x))
```

```{r}
fviz_screeplot(fit.pca, addlabels=TRUE)
```

```{r}
indiv_pca <-fviz_pca_ind(fit.pca, habillage = data$diabetes) 
indiv_pca
# indiv_pca +
#   scale_color_manual(values = c("0" = "cyan", "1" = "red"),
#                      breaks = c(0, 1),
#                      labels = c("neg", "pos"),
#                      name = "Individuals - PCA")
```

```{r}
fviz_pca_var(fit.pca, repel = TRUE)
```

```{r}
fviz_pca_biplot(fit.pca, habillage = data$diabetes)
```

### Interprétation

# Question 2 - Prédiction par régression logistique

## 2.1 Régression logistique

**Faire une base test indépendante** ie séparer les données en deux sets : training_data et test_data.
Par ex 80% et 20% des données exploitables.
S'assurer de la meme proportion pos/neg dans les deux sets?

Pour réaliser une régression logistique, il est nécessaire d'avoir un **nombre suffisant de données**.
En pratique, il est recommandé d'avoir au moins **10 fois plus d'événements que de paramètres dans le modèle**.
Ici, on a des centaines d'observations (pour chaque label), pour moins de 10 paramètres donc il y a suffisamment de données.

```{r Base test indépendante}
nb_obs = NROW(X)
cut = round(0.8*nb_obs)
training_X = X[1:cut,]
training_y = y[1:cut]
test_X = X[cut+1:nb_obs,]
test_y = y[cut+1:nb_obs]

```

A ce stade, on a juste fait un régression selon une seule variable.
Il faut aller regarder du côté de la régression logistique **multinomiale** pour prendre en compte tous les facteurs...

```{r Régression logistique}
# On utilise y qui a des valeurs binaires ("neg" et "pos" ne peuvent pas être traités pour la régression logistique)
# X ne contient pas les ID qui ne sont pas une variable explicative 
model <- glm(training_y ~ ., data = training_X, family = "binomial")
summary(model)
```

```{r}
coefficients <- coef(model)

# Créer un dataframe pour les coefficients
coefficients_df <- data.frame(variable = names(coefficients), coefficient = coefficients)

# Tracer le graphique des coefficients
ggplot(coefficients_df, aes(x = variable, y = coefficient)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  labs(title = "Graphique des Coefficients", x = "Variables", y = "Coefficient")
```

On pourrait regarder les *odd ratios* OR qui représentent l'influence d'un paramètre --\> A creuser ...

## 2.2. Calculs

## 2.3. Pénalité ℓ1 + ℓ2.

## 2.4. Modèle de régression logistique pénalisée ℓ1 +ℓ2

pour prédire la variable diabetes à partir de l'ensemble des facteurs de risque.
Quelles variables semblent les plus pertinentes ?
Reporter les indicateurs de qualités de cette régression logistique pénalisée ℓ1 + ℓ2.

Remarque 1.
Vous veillerez à optimiser les paramètres de ce modèle par cross-validation.

Remarque 2.
En utilisant l'argument weights de la fonction glmnet(), il est possible de gérer le déséquilibre des classes.

## 2.5. Comparaison avec la selection de variable pas - à - pas

Comparer vos résultats issus de la régression logistique pénalisée ℓ1 + ℓ2 au résultat d'une méthode de

sélection de variables pas-à-pas (step() en R).

## 2.6. Conclusion
